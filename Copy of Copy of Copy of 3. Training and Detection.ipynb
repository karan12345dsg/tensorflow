{"cells":[{"cell_type":"markdown","metadata":{"id":"QUANWN3rpfC9"},"source":["# 0. Setup Paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"146BB11JpfDA"},"outputs":[],"source":["import os"]},{"cell_type":"markdown","metadata":{"id":"CpkYPF4weOl8"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42hJEdo_pfDB"},"outputs":[],"source":["CUSTOM_MODEL_NAME = 'myss_mobilenet_colab2'\n","PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n","PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n","TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n","LABEL_MAP_NAME = 'label_map.pbtxt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbPhYVy_pfDB"},"outputs":[],"source":["paths = {\n","    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n","    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n","    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n","    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n","    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n","    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n","    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n","    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n","    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n","    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n","    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n","    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n"," }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwhWZMI0pfDC"},"outputs":[],"source":["files = {\n","    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n","    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n","    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HR-TfDGrpfDC"},"outputs":[],"source":["for path in paths.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"markdown","metadata":{"id":"OLU-rs_ipfDE"},"source":["# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DeHxXPxBMo4J"},"outputs":[],"source":["# https://www.tensorflow.org/install/source_windows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-Cmz2edpfDE","scrolled":true},"outputs":[],"source":["if os.name=='nt':\n","    !pip install wget\n","    import wget"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iA1DIq5OpfDE"},"outputs":[],"source":["if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n","    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJjMHbnDs3Tv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652549993998,"user_tz":-330,"elapsed":10547,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"}},"outputId":"f9475d83-6a7a-49a4-90bf-5ff5558040b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","The following packages were automatically installed and are no longer required:\n","  libnvidia-common-460 nsight-compute-2020.2.0\n","Use 'apt autoremove' to remove them.\n","0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n","Processing /content/Tensorflow/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.38.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.0)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.25.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n","Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: tensorflow-text~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.2.52)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.20.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.1)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.25.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.3)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.6.8)\n","Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.4.11)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.20.3)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1692480 sha256=4708db9ea567efaa189e69a8fd1e7a36a443a234514f6fd8b8030a25ffd06e7b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nlkmgk_5/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","  Attempting uninstall: object-detection\n","    Found existing installation: object-detection 0.1\n","    Uninstalling object-detection-0.1:\n","      Successfully uninstalled object-detection-0.1\n","Successfully installed object-detection-0.1\n"]}],"source":["# Install Tensorflow Object Detection \n","if os.name=='posix':  \n","    !apt-get install protobuf-compiler\n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n","    \n","if os.name=='nt':\n","    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n","    wget.download(url)\n","    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n","    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n","    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n","    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n","    !cd Tensorflow/models/research/slim && pip install -e . "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Da16-UslMo4N","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652550029365,"user_tz":-330,"elapsed":35397,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"}},"outputId":"b0fd680d-dc69-4fbb-e5e9-62d0444e082d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running tests under Python 3.7.13: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-05-14 17:39:58.773304: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0514 17:39:58.989504 139917107369856 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.36s\n","I0514 17:39:59.347085 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.36s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.47s\n","I0514 17:39:59.818574 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.47s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n","I0514 17:40:00.066284 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.25s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n","I0514 17:40:00.288290 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.93s\n","I0514 17:40:02.215710 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.93s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0514 17:40:02.216967 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n","I0514 17:40:02.252890 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0514 17:40:02.273138 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0514 17:40:02.295915 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n","I0514 17:40:02.444938 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n","I0514 17:40:02.584394 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n","I0514 17:40:02.731835 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","I0514 17:40:02.901310 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.17s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.2s\n","I0514 17:40:03.106857 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.2s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n","I0514 17:40:03.178753 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.07s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0514 17:40:03.520900 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0514 17:40:03.521124 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0514 17:40:03.521231 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0514 17:40:03.524725 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:03.549441 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:03.549593 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:03.650832 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:03.650995 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:03.872044 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:03.872250 139917107369856 efficientnet_model.py:144] round_filter input=40 output=40\n","I0514 17:40:04.084638 139917107369856 efficientnet_model.py:144] round_filter input=40 output=40\n","I0514 17:40:04.084851 139917107369856 efficientnet_model.py:144] round_filter input=80 output=80\n","I0514 17:40:04.568250 139917107369856 efficientnet_model.py:144] round_filter input=80 output=80\n","I0514 17:40:04.568453 139917107369856 efficientnet_model.py:144] round_filter input=112 output=112\n","I0514 17:40:05.005976 139917107369856 efficientnet_model.py:144] round_filter input=112 output=112\n","I0514 17:40:05.006191 139917107369856 efficientnet_model.py:144] round_filter input=192 output=192\n","I0514 17:40:05.852211 139917107369856 efficientnet_model.py:144] round_filter input=192 output=192\n","I0514 17:40:05.852446 139917107369856 efficientnet_model.py:144] round_filter input=320 output=320\n","I0514 17:40:05.968827 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0514 17:40:06.013585 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:06.098106 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0514 17:40:06.098307 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0514 17:40:06.098422 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0514 17:40:06.100869 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:06.129361 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:06.131925 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:06.375357 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:06.375578 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:06.872379 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:06.872592 139917107369856 efficientnet_model.py:144] round_filter input=40 output=40\n","I0514 17:40:07.248973 139917107369856 efficientnet_model.py:144] round_filter input=40 output=40\n","I0514 17:40:07.249202 139917107369856 efficientnet_model.py:144] round_filter input=80 output=80\n","I0514 17:40:07.862361 139917107369856 efficientnet_model.py:144] round_filter input=80 output=80\n","I0514 17:40:07.862575 139917107369856 efficientnet_model.py:144] round_filter input=112 output=112\n","I0514 17:40:08.415005 139917107369856 efficientnet_model.py:144] round_filter input=112 output=112\n","I0514 17:40:08.415217 139917107369856 efficientnet_model.py:144] round_filter input=192 output=192\n","I0514 17:40:09.223071 139917107369856 efficientnet_model.py:144] round_filter input=192 output=192\n","I0514 17:40:09.223277 139917107369856 efficientnet_model.py:144] round_filter input=320 output=320\n","I0514 17:40:09.487703 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0514 17:40:09.542982 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:09.753922 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0514 17:40:09.754149 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0514 17:40:09.754242 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0514 17:40:09.756662 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:09.796547 139917107369856 efficientnet_model.py:144] round_filter input=32 output=32\n","I0514 17:40:09.796708 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:10.039827 139917107369856 efficientnet_model.py:144] round_filter input=16 output=16\n","I0514 17:40:10.040043 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:10.567332 139917107369856 efficientnet_model.py:144] round_filter input=24 output=24\n","I0514 17:40:10.567560 139917107369856 efficientnet_model.py:144] round_filter input=40 output=48\n","I0514 17:40:10.969181 139917107369856 efficientnet_model.py:144] round_filter input=40 output=48\n","I0514 17:40:10.969413 139917107369856 efficientnet_model.py:144] round_filter input=80 output=88\n","I0514 17:40:11.500245 139917107369856 efficientnet_model.py:144] round_filter input=80 output=88\n","I0514 17:40:11.502952 139917107369856 efficientnet_model.py:144] round_filter input=112 output=120\n","I0514 17:40:12.008025 139917107369856 efficientnet_model.py:144] round_filter input=112 output=120\n","I0514 17:40:12.008239 139917107369856 efficientnet_model.py:144] round_filter input=192 output=208\n","I0514 17:40:12.722538 139917107369856 efficientnet_model.py:144] round_filter input=192 output=208\n","I0514 17:40:12.722767 139917107369856 efficientnet_model.py:144] round_filter input=320 output=352\n","I0514 17:40:13.053605 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=1408\n","I0514 17:40:13.154872 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:13.286402 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0514 17:40:13.286617 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0514 17:40:13.286711 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0514 17:40:13.289907 139917107369856 efficientnet_model.py:144] round_filter input=32 output=40\n","I0514 17:40:13.312733 139917107369856 efficientnet_model.py:144] round_filter input=32 output=40\n","I0514 17:40:13.312888 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:13.716098 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:13.716271 139917107369856 efficientnet_model.py:144] round_filter input=24 output=32\n","I0514 17:40:13.922713 139917107369856 efficientnet_model.py:144] round_filter input=24 output=32\n","I0514 17:40:13.922866 139917107369856 efficientnet_model.py:144] round_filter input=40 output=48\n","I0514 17:40:14.129562 139917107369856 efficientnet_model.py:144] round_filter input=40 output=48\n","I0514 17:40:14.129725 139917107369856 efficientnet_model.py:144] round_filter input=80 output=96\n","I0514 17:40:14.493616 139917107369856 efficientnet_model.py:144] round_filter input=80 output=96\n","I0514 17:40:14.493781 139917107369856 efficientnet_model.py:144] round_filter input=112 output=136\n","I0514 17:40:14.846246 139917107369856 efficientnet_model.py:144] round_filter input=112 output=136\n","I0514 17:40:14.846421 139917107369856 efficientnet_model.py:144] round_filter input=192 output=232\n","I0514 17:40:15.276650 139917107369856 efficientnet_model.py:144] round_filter input=192 output=232\n","I0514 17:40:15.276820 139917107369856 efficientnet_model.py:144] round_filter input=320 output=384\n","I0514 17:40:15.418776 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=1536\n","I0514 17:40:15.446454 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:15.509672 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0514 17:40:15.509804 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0514 17:40:15.509875 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0514 17:40:15.511363 139917107369856 efficientnet_model.py:144] round_filter input=32 output=48\n","I0514 17:40:15.526398 139917107369856 efficientnet_model.py:144] round_filter input=32 output=48\n","I0514 17:40:15.526507 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:15.635046 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:15.635172 139917107369856 efficientnet_model.py:144] round_filter input=24 output=32\n","I0514 17:40:15.915188 139917107369856 efficientnet_model.py:144] round_filter input=24 output=32\n","I0514 17:40:15.915343 139917107369856 efficientnet_model.py:144] round_filter input=40 output=56\n","I0514 17:40:16.191163 139917107369856 efficientnet_model.py:144] round_filter input=40 output=56\n","I0514 17:40:16.191345 139917107369856 efficientnet_model.py:144] round_filter input=80 output=112\n","I0514 17:40:16.640436 139917107369856 efficientnet_model.py:144] round_filter input=80 output=112\n","I0514 17:40:16.640617 139917107369856 efficientnet_model.py:144] round_filter input=112 output=160\n","I0514 17:40:17.071388 139917107369856 efficientnet_model.py:144] round_filter input=112 output=160\n","I0514 17:40:17.071557 139917107369856 efficientnet_model.py:144] round_filter input=192 output=272\n","I0514 17:40:17.647388 139917107369856 efficientnet_model.py:144] round_filter input=192 output=272\n","I0514 17:40:17.647555 139917107369856 efficientnet_model.py:144] round_filter input=320 output=448\n","I0514 17:40:17.784090 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=1792\n","I0514 17:40:17.809923 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:18.076309 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0514 17:40:18.076493 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0514 17:40:18.076570 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0514 17:40:18.078097 139917107369856 efficientnet_model.py:144] round_filter input=32 output=48\n","I0514 17:40:18.092578 139917107369856 efficientnet_model.py:144] round_filter input=32 output=48\n","I0514 17:40:18.092695 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:18.265364 139917107369856 efficientnet_model.py:144] round_filter input=16 output=24\n","I0514 17:40:18.265517 139917107369856 efficientnet_model.py:144] round_filter input=24 output=40\n","I0514 17:40:18.630104 139917107369856 efficientnet_model.py:144] round_filter input=24 output=40\n","I0514 17:40:18.630269 139917107369856 efficientnet_model.py:144] round_filter input=40 output=64\n","I0514 17:40:18.986947 139917107369856 efficientnet_model.py:144] round_filter input=40 output=64\n","I0514 17:40:18.987114 139917107369856 efficientnet_model.py:144] round_filter input=80 output=128\n","I0514 17:40:19.484386 139917107369856 efficientnet_model.py:144] round_filter input=80 output=128\n","I0514 17:40:19.484555 139917107369856 efficientnet_model.py:144] round_filter input=112 output=176\n","I0514 17:40:19.979651 139917107369856 efficientnet_model.py:144] round_filter input=112 output=176\n","I0514 17:40:19.979833 139917107369856 efficientnet_model.py:144] round_filter input=192 output=304\n","I0514 17:40:20.621865 139917107369856 efficientnet_model.py:144] round_filter input=192 output=304\n","I0514 17:40:20.622040 139917107369856 efficientnet_model.py:144] round_filter input=320 output=512\n","I0514 17:40:20.833461 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=2048\n","I0514 17:40:20.859544 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:20.944222 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0514 17:40:20.944400 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0514 17:40:20.944481 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0514 17:40:20.946026 139917107369856 efficientnet_model.py:144] round_filter input=32 output=56\n","I0514 17:40:20.962587 139917107369856 efficientnet_model.py:144] round_filter input=32 output=56\n","I0514 17:40:20.962701 139917107369856 efficientnet_model.py:144] round_filter input=16 output=32\n","I0514 17:40:21.128344 139917107369856 efficientnet_model.py:144] round_filter input=16 output=32\n","I0514 17:40:21.128516 139917107369856 efficientnet_model.py:144] round_filter input=24 output=40\n","I0514 17:40:21.553781 139917107369856 efficientnet_model.py:144] round_filter input=24 output=40\n","I0514 17:40:21.553956 139917107369856 efficientnet_model.py:144] round_filter input=40 output=72\n","I0514 17:40:21.974618 139917107369856 efficientnet_model.py:144] round_filter input=40 output=72\n","I0514 17:40:21.974794 139917107369856 efficientnet_model.py:144] round_filter input=80 output=144\n","I0514 17:40:22.550057 139917107369856 efficientnet_model.py:144] round_filter input=80 output=144\n","I0514 17:40:22.550238 139917107369856 efficientnet_model.py:144] round_filter input=112 output=200\n","I0514 17:40:23.380236 139917107369856 efficientnet_model.py:144] round_filter input=112 output=200\n","I0514 17:40:23.380441 139917107369856 efficientnet_model.py:144] round_filter input=192 output=344\n","I0514 17:40:24.165368 139917107369856 efficientnet_model.py:144] round_filter input=192 output=344\n","I0514 17:40:24.165546 139917107369856 efficientnet_model.py:144] round_filter input=320 output=576\n","I0514 17:40:24.375215 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=2304\n","I0514 17:40:24.401272 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0514 17:40:24.500409 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0514 17:40:24.500589 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0514 17:40:24.500672 139917107369856 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0514 17:40:24.502367 139917107369856 efficientnet_model.py:144] round_filter input=32 output=64\n","I0514 17:40:24.522655 139917107369856 efficientnet_model.py:144] round_filter input=32 output=64\n","I0514 17:40:24.522814 139917107369856 efficientnet_model.py:144] round_filter input=16 output=32\n","I0514 17:40:24.763023 139917107369856 efficientnet_model.py:144] round_filter input=16 output=32\n","I0514 17:40:24.763192 139917107369856 efficientnet_model.py:144] round_filter input=24 output=48\n","I0514 17:40:25.266313 139917107369856 efficientnet_model.py:144] round_filter input=24 output=48\n","I0514 17:40:25.266509 139917107369856 efficientnet_model.py:144] round_filter input=40 output=80\n","I0514 17:40:25.760800 139917107369856 efficientnet_model.py:144] round_filter input=40 output=80\n","I0514 17:40:25.760980 139917107369856 efficientnet_model.py:144] round_filter input=80 output=160\n","I0514 17:40:26.463845 139917107369856 efficientnet_model.py:144] round_filter input=80 output=160\n","I0514 17:40:26.464023 139917107369856 efficientnet_model.py:144] round_filter input=112 output=224\n","I0514 17:40:27.167321 139917107369856 efficientnet_model.py:144] round_filter input=112 output=224\n","I0514 17:40:27.167507 139917107369856 efficientnet_model.py:144] round_filter input=192 output=384\n","I0514 17:40:28.105297 139917107369856 efficientnet_model.py:144] round_filter input=192 output=384\n","I0514 17:40:28.105503 139917107369856 efficientnet_model.py:144] round_filter input=320 output=640\n","I0514 17:40:28.663052 139917107369856 efficientnet_model.py:144] round_filter input=1280 output=2560\n","I0514 17:40:28.689854 139917107369856 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.63s\n","I0514 17:40:28.808407 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 25.63s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0514 17:40:28.815120 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0514 17:40:28.817066 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0514 17:40:28.817626 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0514 17:40:28.819097 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0514 17:40:28.820399 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0514 17:40:28.820837 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0514 17:40:28.821751 139917107369856 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 30.835s\n","\n","OK (skipped=1)\n"]}],"source":["VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n","# Verify Installation\n","!python {VERIFICATION_SCRIPT}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3121,"status":"ok","timestamp":1652550032459,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"kwLGAYrbMo4O","outputId":"f9ef8f13-2f71-42ca-afb2-cb26aee38556"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.20.1)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"]}],"source":["!pip install tensorflow --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"collapsed":true,"executionInfo":{"elapsed":11162,"status":"ok","timestamp":1652550043604,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"uSnX7VkZMo4O","outputId":"188a6f58-30b2-4f55-8c33-7aebe1bd6fe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: protobuf 3.20.1\n","Uninstalling protobuf-3.20.1:\n","  Successfully uninstalled protobuf-3.20.1\n","Found existing installation: matplotlib 3.2.0\n","Uninstalling matplotlib-3.2.0:\n","  Successfully uninstalled matplotlib-3.2.0\n","Collecting protobuf\n","  Using cached protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","Collecting matplotlib==3.2\n","  Using cached matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.11.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.21.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (3.0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.2) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.15.0)\n","Installing collected packages: protobuf, matplotlib\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed matplotlib-3.2.0 protobuf-3.20.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","matplotlib","mpl_toolkits"]}}},"metadata":{}}],"source":["!pip uninstall protobuf matplotlib -y\n","!pip install protobuf matplotlib==3.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80-klK8XMo4P"},"outputs":[],"source":["import object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":985,"status":"ok","timestamp":1652550045222,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"6a6APxpKMo4P","outputId":"8a22e578-5b34-4f70-cd96-d918a2fb8e17","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Package                       Version\n","----------------------------- ---------------------\n","absl-py                       1.0.0\n","alabaster                     0.7.12\n","albumentations                0.1.12\n","altair                        4.2.0\n","apache-beam                   2.38.0\n","appdirs                       1.4.4\n","argon2-cffi                   21.3.0\n","argon2-cffi-bindings          21.2.0\n","arviz                         0.12.0\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","atari-py                      0.2.9\n","atomicwrites                  1.4.0\n","attrs                         21.4.0\n","audioread                     2.1.9\n","autograd                      1.4\n","avro-python3                  1.10.2\n","Babel                         2.10.1\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        5.0.0\n","blis                          0.4.1\n","bokeh                         2.3.3\n","Bottleneck                    1.3.4\n","branca                        0.5.0\n","bs4                           0.0.1\n","CacheControl                  0.12.11\n","cached-property               1.5.2\n","cachetools                    4.2.4\n","catalogue                     1.0.0\n","certifi                       2021.10.8\n","cffi                          1.15.0\n","cftime                        1.6.0\n","chardet                       3.0.4\n","charset-normalizer            2.0.12\n","click                         7.1.2\n","cloudpickle                   2.0.0\n","cmake                         3.22.4\n","cmdstanpy                     0.9.5\n","colorama                      0.4.4\n","colorcet                      3.0.0\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","contextlib2                   0.5.5\n","convertdate                   2.4.0\n","coverage                      3.7.1\n","coveralls                     0.5\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cupy-cuda111                  9.4.0\n","cvxopt                        1.2.7\n","cvxpy                         1.0.31\n","cycler                        0.11.0\n","cymem                         2.0.6\n","Cython                        0.29.28\n","daft                          0.0.4\n","dask                          2.12.0\n","datascience                   0.10.6\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.1.1\n","distributed                   1.25.3\n","dlib                          19.18.0\n","dm-tree                       0.1.7\n","docopt                        0.6.2\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.307\n","easydict                      1.9\n","ecos                          2.0.10\n","editdistance                  0.5.3\n","en-core-web-sm                2.2.5\n","entrypoints                   0.4\n","ephem                         4.1.3\n","et-xmlfile                    1.1.0\n","fa2                           0.3.5\n","fastai                        1.0.61\n","fastavro                      1.4.11\n","fastdtw                       0.3.4\n","fastjsonschema                2.15.3\n","fastprogress                  1.0.2\n","fastrlock                     0.8\n","fbprophet                     0.7.1\n","feather-format                0.4.1\n","filelock                      3.6.0\n","firebase-admin                4.4.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   2.0\n","folium                        0.8.3\n","future                        0.16.0\n","gast                          0.5.3\n","GDAL                          2.2.2\n","gdown                         4.4.0\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               1.31.5\n","google-api-python-client      1.12.11\n","google-auth                   1.35.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         1.21.0\n","google-cloud-bigquery-storage 1.1.1\n","google-cloud-core             1.0.3\n","google-cloud-datastore        1.8.0\n","google-cloud-firestore        1.7.0\n","google-cloud-language         1.2.0\n","google-cloud-storage          1.18.1\n","google-cloud-translate        1.5.0\n","google-colab                  1.0.0\n","google-pasta                  0.2.0\n","google-resumable-media        0.4.1\n","googleapis-common-protos      1.56.0\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      1.1.2\n","grpcio                        1.44.0\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.17.3\n","h5py                          3.1.0\n","hdfs                          2.7.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.3\n","holidays                      0.10.5.2\n","holoviews                     1.14.8\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httplib2shim                  0.0.3\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","ideep4py                      2.0.0.post3\n","idna                          2.10\n","imageio                       2.4.1\n","imagesize                     1.3.0\n","imbalanced-learn              0.8.1\n","imblearn                      0.0\n","imgaug                        0.2.9\n","importlib-metadata            4.11.3\n","importlib-resources           5.7.1\n","imutils                       0.5.4\n","inflect                       2.1.0\n","iniconfig                     1.1.1\n","intel-openmp                  2022.1.0\n","intervaltree                  2.1.0\n","ipykernel                     4.10.1\n","ipython                       5.5.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.7.0\n","itsdangerous                  1.1.0\n","jax                           0.3.8\n","jaxlib                        0.3.7+cuda11.cudnn805\n","jedi                          0.18.1\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.1.0\n","jpeg4py                       0.1.4\n","jsonschema                    4.3.3\n","jupyter                       1.0.0\n","jupyter-client                5.3.5\n","jupyter-console               5.2.0\n","jupyter-core                  4.10.0\n","jupyterlab-pygments           0.2.2\n","jupyterlab-widgets            1.1.0\n","kaggle                        1.5.12\n","kapre                         0.3.7\n","keras                         2.8.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.2\n","korean-lunar-calendar         0.2.1\n","libclang                      14.0.1\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.34.0\n","lmdb                          0.99\n","LunarCalendar                 0.0.9\n","lvis                          0.5.3\n","lxml                          4.2.6\n","Markdown                      3.3.6\n","MarkupSafe                    2.0.1\n","matplotlib                    3.2.0\n","matplotlib-inline             0.1.3\n","matplotlib-venn               0.11.7\n","missingno                     0.5.1\n","mistune                       0.8.4\n","mizani                        0.6.0\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                8.12.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.3\n","multiprocess                  0.70.12.2\n","multitasking                  0.0.10\n","murmurhash                    1.0.7\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbclient                      0.6.2\n","nbconvert                     5.6.1\n","nbformat                      5.3.0\n","nest-asyncio                  1.5.5\n","netCDF4                       1.5.8\n","networkx                      2.6.3\n","nibabel                       3.0.2\n","nltk                          3.2.5\n","notebook                      5.3.1\n","numba                         0.51.2\n","numexpr                       2.8.1\n","numpy                         1.21.6\n","nvidia-ml-py3                 7.352.0\n","oauth2client                  4.1.3\n","oauthlib                      3.2.0\n","object-detection              0.1\n","okgrade                       0.4.3\n","opencv-contrib-python         4.1.2.30\n","opencv-python                 4.1.2.30\n","opencv-python-headless        4.5.2.52\n","openpyxl                      3.0.9\n","opt-einsum                    3.3.0\n","orjson                        3.6.8\n","osqp                          0.6.2.post0\n","packaging                     21.3\n","palettable                    3.3.0\n","pandas                        1.3.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.13.3\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.12.1\n","parso                         0.8.3\n","pathlib                       1.0.1\n","patsy                         0.5.2\n","pep517                        0.12.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","plac                          1.1.3\n","plotly                        5.5.0\n","plotnine                      0.6.0\n","pluggy                        0.7.1\n","pooch                         1.6.0\n","portalocker                   2.4.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.1\n","preshed                       3.0.6\n","prettytable                   3.2.0\n","progressbar2                  3.38.0\n","prometheus-client             0.14.1\n","promise                       2.3\n","prompt-toolkit                1.0.18\n","proto-plus                    1.20.3\n","protobuf                      3.20.1\n","psutil                        5.4.8\n","psycopg2                      2.7.6.1\n","ptyprocess                    0.7.0\n","py                            1.11.0\n","py-cpuinfo                    8.0.0\n","pyarrow                       6.0.1\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.4\n","pycparser                     2.21\n","pyct                          0.4.8\n","pydata-google-auth            1.4.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0.1\n","pyglet                        1.5.0\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pymc3                         3.11.4\n","PyMeeus                       0.5.11\n","pymongo                       3.12.3\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.8\n","pyrsistent                    0.18.1\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        2.19.1.1\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-chess                  0.23.11\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                6.1.2\n","python-utils                  3.1.0\n","pytz                          2022.1\n","pyviz-comms                   2.2.0\n","PyWavelets                    1.3.0\n","PyYAML                        5.4.1\n","pyzmq                         22.3.0\n","qdldl                         0.1.5.post2\n","qtconsole                     5.3.0\n","QtPy                          2.1.0\n","regex                         2019.12.20\n","requests                      2.27.1\n","requests-oauthlib             1.3.1\n","resampy                       0.2.2\n","rpy2                          3.4.5\n","rsa                           4.8\n","sacrebleu                     2.0.0\n","scikit-image                  0.18.3\n","scikit-learn                  1.0.2\n","scipy                         1.4.1\n","screen-resolution-extra       0.0.0\n","scs                           3.2.0\n","seaborn                       0.11.2\n","semver                        2.13.0\n","Send2Trash                    1.8.0\n","sentencepiece                 0.1.96\n","seqeval                       1.2.2\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.8.1.post1\n","simplegeneric                 0.8.1\n","six                           1.15.0\n","sklearn                       0.0\n","sklearn-pandas                1.8.0\n","smart-open                    6.0.0\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","SoundFile                     0.10.3.post1\n","soupsieve                     2.3.2.post1\n","spacy                         2.2.4\n","Sphinx                        1.8.6\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.36\n","sqlparse                      0.4.2\n","srsly                         1.0.5\n","statsmodels                   0.10.2\n","sympy                         1.7.1\n","tables                        3.7.0\n","tabulate                      0.8.9\n","tblib                         1.7.0\n","tenacity                      8.0.1\n","tensorboard                   2.8.0\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.1\n","tensorflow                    2.8.0\n","tensorflow-addons             0.16.1\n","tensorflow-datasets           4.0.1\n","tensorflow-estimator          2.8.0\n","tensorflow-gcs-config         2.8.0\n","tensorflow-hub                0.12.0\n","tensorflow-io                 0.25.0\n","tensorflow-io-gcs-filesystem  0.25.0\n","tensorflow-metadata           1.7.0\n","tensorflow-model-optimization 0.7.2\n","tensorflow-probability        0.16.0\n","tensorflow-text               2.8.2\n","termcolor                     1.1.0\n","terminado                     0.13.3\n","testpath                      0.6.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","tf-estimator-nightly          2.8.0.dev2021122109\n","tf-models-official            2.8.0\n","tf-slim                       1.1.0\n","Theano-PyMC                   1.1.2\n","thinc                         7.4.0\n","threadpoolctl                 3.1.0\n","tifffile                      2021.11.2\n","tinycss2                      1.1.1\n","tomli                         2.0.1\n","toolz                         0.11.2\n","torch                         1.11.0+cu113\n","torchaudio                    0.11.0+cu113\n","torchsummary                  1.5.1\n","torchtext                     0.12.0\n","torchvision                   0.12.0+cu113\n","tornado                       5.1.1\n","tqdm                          4.64.0\n","traitlets                     5.1.1\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typing-extensions             4.2.0\n","tzlocal                       1.5.1\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.9.1\n","wcwidth                       0.2.5\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.37.1\n","widgetsnbextension            3.6.0\n","wordcloud                     1.5.0\n","wrapt                         1.14.0\n","xarray                        0.18.2\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.1.0\n","xlwt                          1.3.0\n","yellowbrick                   1.4\n","zict                          2.2.0\n","zipp                          3.8.0\n"]}],"source":["!pip list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1652550045633,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"csofht2npfDE","outputId":"18b0c140-5ee5-44d9-f235-2da66a6887c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-14 17:40:45--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.45.112, 2607:f8b0:4004:83f::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.45.112|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","\n","\r          ssd_mobil   0%[                    ]       0  --.-KB/s               \rssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n","\n","2022-05-14 17:40:45 (202 MB/s) - ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz saved [20515344/20515344]\n","\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"]}],"source":["if os.name =='posix':\n","    !wget {PRETRAINED_MODEL_URL}\n","    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n","if os.name == 'nt':\n","    wget.download(PRETRAINED_MODEL_URL)\n","    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n","    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"]},{"cell_type":"markdown","metadata":{"id":"M5KJTnkfpfDC"},"source":["# 2. Create Label Map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1BVDWo7pfDC"},"outputs":[],"source":["labels = [{'name':'A', 'id':1}, {'name':'B', 'id':2}, {'name':'C', 'id':3}, {'name':'D', 'id':4},\n","          {'name':'E', 'id':5}, {'name':'F', 'id':6}, {'name':'G', 'id':7}, {'name':'H', 'id':8},\n","          {'name':'I', 'id':9}, {'name':'J', 'id':10}, {'name':'K', 'id':11}, {'name':'L', 'id':12},\n","          {'name':'M', 'id':13}, {'name':'N', 'id':14}, {'name':'O', 'id':15}, {'name':'P', 'id':16},\n","          {'name':'Q', 'id':17}, {'name':'R', 'id':18}, {'name':'S', 'id':19}, {'name':'T', 'id':20},\n","          {'name':'U', 'id':21}, {'name':'V', 'id':22}, {'name':'W', 'id':23}, {'name':'X', 'id':24},\n","           {'name':'Y', 'id':25}, {'name':'Z', 'id':26}, {'name':'space', 'id':27}, {'name':'del', 'id':28}\n","           \n","         ]"]},{"cell_type":"markdown","metadata":{"id":"C88zyVELpfDC"},"source":["# 3. Create TF records"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1652550046207,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"kvf5WccwrFGq","outputId":"d4767fb8-8d03-441a-811f-f1ec1bd618d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow/workspace/images/train/\n","Tensorflow/workspace/images/train/A.bd002a57-c4d3-11ec-a23c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.bd002a57-c4d3-11ec-a23c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.be3b7d78-c4d3-11ec-891a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.be3b7d78-c4d3-11ec-891a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.bf736b57-c4d3-11ec-8e35-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.bf736b57-c4d3-11ec-8e35-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.c0a93027-c4d3-11ec-a531-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.c0a93027-c4d3-11ec-a531-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.c1def861-c4d3-11ec-8332-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.c1def861-c4d3-11ec-8332-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.cb618893-c939-11ec-a3c7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.cb618893-c939-11ec-a3c7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.cdcf0c8a-c939-11ec-a323-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.cdcf0c8a-c939-11ec-a323-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.cf02c2d2-c939-11ec-968f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.cf02c2d2-c939-11ec-968f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.d0365aff-c939-11ec-a58d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.d0365aff-c939-11ec-a58d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.d16aba95-c939-11ec-9f4d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.d16aba95-c939-11ec-9f4d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.d29f18ac-c939-11ec-8582-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.d29f18ac-c939-11ec-8582-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.d3d2e10c-c939-11ec-b055-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.d3d2e10c-c939-11ec-b055-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.d5066627-c939-11ec-8c71-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.d5066627-c939-11ec-8c71-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f0f80ae8-c939-11ec-ac45-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f0f80ae8-c939-11ec-ac45-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f230d72d-c939-11ec-8024-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f230d72d-c939-11ec-8024-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f3667d90-c939-11ec-ba65-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f3667d90-c939-11ec-ba65-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f49c73ac-c939-11ec-9784-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f49c73ac-c939-11ec-9784-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f5d1691a-c939-11ec-98d0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f5d1691a-c939-11ec-98d0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f83a835a-c939-11ec-8401-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f83a835a-c939-11ec-8401-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.f9705cfe-c939-11ec-9529-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.f9705cfe-c939-11ec-9529-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/A.faa500db-c939-11ec-b388-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/A.faa500db-c939-11ec-b388-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.1bdcfd93-c4d6-11ec-98a4-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.1bdcfd93-c4d6-11ec-98a4-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.1d18af74-c4d6-11ec-9004-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.1d18af74-c4d6-11ec-9004-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.1e505835-c4d6-11ec-ba51-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.1e505835-c4d6-11ec-ba51-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.1f863a96-c4d6-11ec-8495-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.1f863a96-c4d6-11ec-8495-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.20bb59fa-c4d6-11ec-8f60-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.20bb59fa-c4d6-11ec-8f60-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.329d5a0b-c93a-11ec-bf3f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.329d5a0b-c93a-11ec-bf3f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.33d80fcf-c93a-11ec-bc09-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.33d80fcf-c93a-11ec-bc09-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.350ee02d-c93a-11ec-8915-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.350ee02d-c93a-11ec-8915-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.36436c4b-c93a-11ec-b13b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.36436c4b-c93a-11ec-b13b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.377a8c31-c93a-11ec-9d88-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.377a8c31-c93a-11ec-9d88-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.38ae3118-c93a-11ec-b716-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.38ae3118-c93a-11ec-b716-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.39e1ba75-c93a-11ec-8959-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.39e1ba75-c93a-11ec-8959-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.3b172ddd-c93a-11ec-84f1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.3b172ddd-c93a-11ec-84f1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.3d7fbf83-c93a-11ec-bfd5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.3d7fbf83-c93a-11ec-bfd5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.baa30f2e-c4d5-11ec-936b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.baa30f2e-c4d5-11ec-936b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.bbde7eee-c4d5-11ec-9da9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.bbde7eee-c4d5-11ec-9da9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.be4b1e42-c4d5-11ec-b919-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.be4b1e42-c4d5-11ec-b919-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/B.bf823f29-c4d5-11ec-849e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/B.bf823f29-c4d5-11ec-849e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.65834bf6-c93a-11ec-855e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.65834bf6-c93a-11ec-855e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.66b8d850-c93a-11ec-979c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.66b8d850-c93a-11ec-979c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.67eeaf62-c93a-11ec-95d0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.67eeaf62-c93a-11ec-95d0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.6923ad69-c93a-11ec-b040-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.6923ad69-c93a-11ec-b040-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.6b8efca6-c93a-11ec-9330-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.6b8efca6-c93a-11ec-9330-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.6cc31535-c93a-11ec-8a01-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.6cc31535-c93a-11ec-8a01-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.6df70511-c93a-11ec-a47f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.6df70511-c93a-11ec-a47f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.880ff4d4-c93a-11ec-9257-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.880ff4d4-c93a-11ec-9257-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8945e144-c93a-11ec-8a9a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8945e144-c93a-11ec-8a9a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8a7bdf90-c93a-11ec-a56a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8a7bdf90-c93a-11ec-a56a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8bb1cb17-c93a-11ec-8aa7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8bb1cb17-c93a-11ec-8aa7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8ce73155-c93a-11ec-8320-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8ce73155-c93a-11ec-8320-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8e1b0df8-c93a-11ec-9051-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8e1b0df8-c93a-11ec-9051-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8ed42dd8-c4d6-11ec-99e6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8ed42dd8-c4d6-11ec-99e6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.8f50c076-c93a-11ec-b6ce-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.8f50c076-c93a-11ec-b6ce-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.90102f4e-c4d6-11ec-b232-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.90102f4e-c4d6-11ec-b232-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.914911a0-c4d6-11ec-85b2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.914911a0-c4d6-11ec-85b2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.91bce460-c93a-11ec-b7e2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.91bce460-c93a-11ec-b7e2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.9281375e-c4d6-11ec-915e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.9281375e-c4d6-11ec-915e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.93b6e7e1-c4d6-11ec-b868-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.93b6e7e1-c4d6-11ec-b868-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.bd255bfe-c4d6-11ec-9b78-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.bd255bfe-c4d6-11ec-9b78-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.be63cbfe-c4d6-11ec-a868-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.be63cbfe-c4d6-11ec-a868-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.bf9c8742-c4d6-11ec-aa92-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.bf9c8742-c4d6-11ec-aa92-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.c0d850af-c4d6-11ec-9ac7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.c0d850af-c4d6-11ec-9ac7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/C.c20e3c03-c4d6-11ec-8dae-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/C.c20e3c03-c4d6-11ec-8dae-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/D286.jpg\n","Tensorflow/workspace/images/train/D286.xml\n","Tensorflow/workspace/images/train/D863.jpg\n","Tensorflow/workspace/images/train/D863.xml\n","Tensorflow/workspace/images/train/D864.jpg\n","Tensorflow/workspace/images/train/D864.xml\n","Tensorflow/workspace/images/train/del.ac1fd60b-c4e3-11ec-9fcd-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.ac1fd60b-c4e3-11ec-9fcd-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.ad5b9962-c4e3-11ec-919a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.ad5b9962-c4e3-11ec-919a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.ae919bfe-c4e3-11ec-81de-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.ae919bfe-c4e3-11ec-81de-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.afc6cc14-c4e3-11ec-99ea-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.afc6cc14-c4e3-11ec-99ea-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.b0fb27ae-c4e3-11ec-ae0d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.b0fb27ae-c4e3-11ec-ae0d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.b230cc67-c4e3-11ec-a849-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.b230cc67-c4e3-11ec-a849-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/del.b49d1f61-c4e3-11ec-803a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/del.b49d1f61-c4e3-11ec-803a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.085f95aa-c93c-11ec-a810-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.085f95aa-c93c-11ec-a810-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.0d330236-c93c-11ec-9b50-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.0d330236-c93c-11ec-9b50-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.0e6754e0-c93c-11ec-9e9b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.0e6754e0-c93c-11ec-9e9b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.0f9d63f2-c93c-11ec-b140-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.0f9d63f2-c93c-11ec-b140-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.10d3140e-c93c-11ec-86b2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.10d3140e-c93c-11ec-86b2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.12095774-c93c-11ec-b425-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.12095774-c93c-11ec-b425-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.427ff86c-d379-11ec-86c5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.427ff86c-d379-11ec-86c5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.49c853b0-d379-11ec-ba6f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.49c853b0-d379-11ec-ba6f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.4afec954-d379-11ec-a02b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.4afec954-d379-11ec-a02b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d1877934-c93b-11ec-aa57-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d1877934-c93b-11ec-aa57-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d2c22fba-c93b-11ec-b7b0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d2c22fba-c93b-11ec-b7b0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d3f9e6e5-c93b-11ec-8e62-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d3f9e6e5-c93b-11ec-8e62-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d52f4a50-c93b-11ec-b7cb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d52f4a50-c93b-11ec-b7cb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d6634e5c-c93b-11ec-a9c7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d6634e5c-c93b-11ec-a9c7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.d7977999-c93b-11ec-934c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.d7977999-c93b-11ec-934c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.da01dc21-c93b-11ec-947b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.da01dc21-c93b-11ec-947b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/E.db362dac-c93b-11ec-bea3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/E.db362dac-c93b-11ec-bea3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.71101b58-c93c-11ec-a013-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.71101b58-c93c-11ec-a013-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.7248d706-c93c-11ec-b32b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.7248d706-c93c-11ec-b32b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.737e33c5-c93c-11ec-afe5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.737e33c5-c93c-11ec-afe5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.74b44718-c93c-11ec-9e0d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.74b44718-c93c-11ec-9e0d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.75ea1e2f-c93c-11ec-9b48-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.75ea1e2f-c93c-11ec-9b48-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.771fc9d5-c93c-11ec-82f3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.771fc9d5-c93c-11ec-82f3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.7854693a-c93c-11ec-b892-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.7854693a-c93c-11ec-b892-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.798964f0-c93c-11ec-9376-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.798964f0-c93c-11ec-9376-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.7bf2df06-c93c-11ec-8dd8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.7bf2df06-c93c-11ec-8dd8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.91041986-c93c-11ec-a8ec-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.91041986-c93c-11ec-a8ec-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.923c6658-c93c-11ec-9b26-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.923c6658-c93c-11ec-9b26-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.9371eca5-c93c-11ec-8571-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.9371eca5-c93c-11ec-8571-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.95dd817a-c93c-11ec-afb6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.95dd817a-c93c-11ec-afb6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.9712f43e-c93c-11ec-ade9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.9712f43e-c93c-11ec-ade9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.984745a0-c93c-11ec-8b5e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.984745a0-c93c-11ec-8b5e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.997afd2b-c93c-11ec-b08c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.997afd2b-c93c-11ec-b08c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.9aafb1d4-c93c-11ec-9fde-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.9aafb1d4-c93c-11ec-9fde-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.9be3b5da-c93c-11ec-acbc-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.9be3b5da-c93c-11ec-acbc-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.b71b15ba-c4d8-11ec-9287-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.b71b15ba-c4d8-11ec-9287-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.b8580000-c4d8-11ec-894c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.b8580000-c4d8-11ec-894c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.b98e0b84-c4d8-11ec-ab7e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.b98e0b84-c4d8-11ec-ab7e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.bac356fa-c4d8-11ec-85a0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.bac356fa-c4d8-11ec-85a0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/F.bbfaa65e-c4d8-11ec-bb2e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/F.bbfaa65e-c4d8-11ec-bb2e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.43820186-c93d-11ec-9400-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.43820186-c93d-11ec-9400-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.44bcc17a-c93d-11ec-a070-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.44bcc17a-c93d-11ec-a070-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.45f18f6a-c93d-11ec-be93-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.45f18f6a-c93d-11ec-be93-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.4725ba79-c93d-11ec-9549-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.4725ba79-c93d-11ec-9549-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.485b91e7-c93d-11ec-90b3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.485b91e7-c93d-11ec-90b3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.4990ee81-c93d-11ec-af82-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.4990ee81-c93d-11ec-af82-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.4bf8cf66-c93d-11ec-9f83-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.4bf8cf66-c93d-11ec-9f83-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.4d2ec297-c93d-11ec-aaf5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.4d2ec297-c93d-11ec-aaf5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.4e644d63-c93d-11ec-b459-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.4e644d63-c93d-11ec-b459-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.6bcc92b3-c93d-11ec-913a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.6bcc92b3-c93d-11ec-913a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.6d06bd23-c93d-11ec-83da-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.6d06bd23-c93d-11ec-83da-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.6e3ca311-c93d-11ec-a1cc-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.6e3ca311-c93d-11ec-a1cc-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.6f721269-c93d-11ec-959c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.6f721269-c93d-11ec-959c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.70a6b9eb-c93d-11ec-a702-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.70a6b9eb-c93d-11ec-a702-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.71dcc6e1-c93d-11ec-a1e6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.71dcc6e1-c93d-11ec-a1e6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.744877ab-c93d-11ec-8cdb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.744877ab-c93d-11ec-8cdb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.757cedd7-c93d-11ec-8dab-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.757cedd7-c93d-11ec-8dab-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/G.76b21f3b-c93d-11ec-930e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/G.76b21f3b-c93d-11ec-930e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.aaf1bf0a-c93d-11ec-89ea-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.aaf1bf0a-c93d-11ec-89ea-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.ae8f8011-c93d-11ec-a7d1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.ae8f8011-c93d-11ec-a7d1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.afc514b0-c93d-11ec-a24f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.afc514b0-c93d-11ec-a24f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.b0fa85d3-c93d-11ec-8a0e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.b0fa85d3-c93d-11ec-8a0e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.b2304885-c93d-11ec-8742-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.b2304885-c93d-11ec-8742-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.b365fd13-c93d-11ec-8056-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.b365fd13-c93d-11ec-8056-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.b499b34c-c93d-11ec-b675-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.b499b34c-c93d-11ec-b675-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.ce82493d-c93d-11ec-a457-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.ce82493d-c93d-11ec-a457-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.cfbb2bb0-c93d-11ec-950b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.cfbb2bb0-c93d-11ec-950b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d2250228-c93d-11ec-8436-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d2250228-c93d-11ec-8436-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d35a9e5d-c93d-11ec-b957-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d35a9e5d-c93d-11ec-b957-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d5c3eda3-c93d-11ec-b7c1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d5c3eda3-c93d-11ec-b7c1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d6f8db14-c93d-11ec-a1c9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d6f8db14-c93d-11ec-a1c9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d82eb271-c93d-11ec-9a9f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d82eb271-c93d-11ec-9a9f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.d9648a73-c93d-11ec-870e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.d9648a73-c93d-11ec-870e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.e56c3a8d-c4e3-11ec-86e2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.e56c3a8d-c4e3-11ec-86e2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.e6aa50ac-c4e3-11ec-962c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.e6aa50ac-c4e3-11ec-962c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.e7e02310-c4e3-11ec-9a4d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.e7e02310-c4e3-11ec-9a4d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.e91531d3-c4e3-11ec-895b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.e91531d3-c4e3-11ec-895b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.ea4a7065-c4e3-11ec-a0b0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.ea4a7065-c4e3-11ec-a0b0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.eb801e65-c4e3-11ec-9328-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.eb801e65-c4e3-11ec-9328-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.ecb5b794-c4e3-11ec-8479-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.ecb5b794-c4e3-11ec-8479-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.edebabc7-c4e3-11ec-ab0d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.edebabc7-c4e3-11ec-ab0d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.ef23488f-c4e3-11ec-9f4e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.ef23488f-c4e3-11ec-9f4e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/H.f058411d-c4e3-11ec-9e5e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/H.f058411d-c4e3-11ec-9e5e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.32162ddf-c93e-11ec-a66c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.32162ddf-c93e-11ec-a66c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.334bde2e-c93e-11ec-95dc-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.334bde2e-c93e-11ec-95dc-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.348287de-c93e-11ec-8d2e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.348287de-c93e-11ec-8d2e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.35b6b17f-c93e-11ec-9311-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.35b6b17f-c93e-11ec-9311-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.36ecda70-c93e-11ec-abea-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.36ecda70-c93e-11ec-abea-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.3821654d-c93e-11ec-974a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.3821654d-c93e-11ec-974a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.3956a0a0-c93e-11ec-8f66-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.3956a0a0-c93e-11ec-8f66-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.3bbfa1e5-c93e-11ec-9ce6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.3bbfa1e5-c93e-11ec-9ce6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6515a0d3-c93e-11ec-9528-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6515a0d3-c93e-11ec-9528-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.664e0f20-c93e-11ec-9082-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.664e0f20-c93e-11ec-9082-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6781d7ab-c93e-11ec-abca-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6781d7ab-c93e-11ec-abca-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6b211028-c93e-11ec-a59b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6b211028-c93e-11ec-a59b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6c573539-c93e-11ec-815e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6c573539-c93e-11ec-815e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6d8c97de-c93e-11ec-8f42-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6d8c97de-c93e-11ec-8f42-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6ec1ac45-c93e-11ec-96f7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6ec1ac45-c93e-11ec-96f7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.6ff67327-c93e-11ec-899e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.6ff67327-c93e-11ec-899e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.c7888389-c4dc-11ec-8fee-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.c7888389-c4dc-11ec-8fee-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.c8c2e18f-c4dc-11ec-808f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.c8c2e18f-c4dc-11ec-808f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.c9f93ab3-c4dc-11ec-9201-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.c9f93ab3-c4dc-11ec-9201-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.cb2e9175-c4dc-11ec-a9bb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.cb2e9175-c4dc-11ec-a9bb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.cc63701e-c4dc-11ec-98b9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.cc63701e-c4dc-11ec-98b9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.cd9962df-c4dc-11ec-b55a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.cd9962df-c4dc-11ec-b55a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.ced0effa-c4dc-11ec-9851-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.ced0effa-c4dc-11ec-9851-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.d008fa0e-c4dc-11ec-bd39-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.d008fa0e-c4dc-11ec-bd39-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.d1402a12-c4dc-11ec-8807-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.d1402a12-c4dc-11ec-8807-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/I.d275f60d-c4dc-11ec-9763-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/I.d275f60d-c4dc-11ec-9763-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.18c72c3e-c93f-11ec-932a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.18c72c3e-c93f-11ec-932a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.1b354a79-c93f-11ec-b343-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.1b354a79-c93f-11ec-b343-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.1c690f5c-c93f-11ec-95f3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.1c690f5c-c93f-11ec-95f3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.1d9daff2-c93f-11ec-8e32-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.1d9daff2-c93f-11ec-8e32-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.1ed375b7-c93f-11ec-8dc1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.1ed375b7-c93f-11ec-8dc1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.2007fd73-c93f-11ec-8195-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.2007fd73-c93f-11ec-8195-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.213e9718-c93f-11ec-b951-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.213e9718-c93f-11ec-b951-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.227447d1-c93f-11ec-b7a5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.227447d1-c93f-11ec-b7a5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.23a9ab32-c93f-11ec-9dfa-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/J.23a9ab32-c93f-11ec-9dfa-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (2).jpg\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (2).xml\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (3).jpg\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (3).xml\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (4).jpg\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (4).xml\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (6).jpg\n","Tensorflow/workspace/images/train/J.63f4c7db-c4dd-11ec-92c8-04d4c4df202e (6).xml\n","Tensorflow/workspace/images/train/K.02706a8a-c4de-11ec-bd07-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.02706a8a-c4de-11ec-bd07-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.03ac1026-c4de-11ec-8f81-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.03ac1026-c4de-11ec-8f81-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.04e31f52-c4de-11ec-8c1d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.04e31f52-c4de-11ec-8c1d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.0618bca4-c4de-11ec-9a4e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.0618bca4-c4de-11ec-9a4e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.074e733f-c4de-11ec-8fd0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.074e733f-c4de-11ec-8fd0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.088501ed-c4de-11ec-95e9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.088501ed-c4de-11ec-95e9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.09bb5993-c4de-11ec-921d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.09bb5993-c4de-11ec-921d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.0af0a326-c4de-11ec-97cd-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.0af0a326-c4de-11ec-97cd-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.0d5f259b-c4de-11ec-a411-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.0d5f259b-c4de-11ec-a411-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.61575c7f-c93f-11ec-9c48-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.61575c7f-c93f-11ec-9c48-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.64fb39e8-c93f-11ec-8a0b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.64fb39e8-c93f-11ec-8a0b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.66311279-c93f-11ec-96cf-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.66311279-c93f-11ec-96cf-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.6766635e-c93f-11ec-9f0f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.6766635e-c93f-11ec-9f0f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.689b9e91-c93f-11ec-b948-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.689b9e91-c93f-11ec-b948-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/K.69d0dac9-c93f-11ec-8b94-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/K.69d0dac9-c93f-11ec-8b94-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.0b6dc81a-d299-11ec-860c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.0b6dc81a-d299-11ec-860c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.0ca4a1e8-d299-11ec-9552-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.0ca4a1e8-d299-11ec-9552-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.0ddb933d-d299-11ec-b221-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.0ddb933d-d299-11ec-b221-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.0f12c45d-d299-11ec-9a4e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.0f12c45d-d299-11ec-9a4e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.117dc752-d299-11ec-a18f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.117dc752-d299-11ec-a18f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.12b310af-d299-11ec-9e46-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.12b310af-d299-11ec-9e46-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.13ea0097-d299-11ec-b307-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.13ea0097-d299-11ec-b307-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.151f537d-d299-11ec-b913-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.151f537d-d299-11ec-b913-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.edb3b910-d298-11ec-8e05-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.edb3b910-d298-11ec-8e05-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f01cf75d-d298-11ec-89ac-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f01cf75d-d298-11ec-89ac-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f15359c7-d298-11ec-96f3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f15359c7-d298-11ec-96f3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f28a418b-d298-11ec-b1e2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f28a418b-d298-11ec-b1e2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f4f6d2f1-d298-11ec-9c4d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f4f6d2f1-d298-11ec-9c4d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f62d6d32-d298-11ec-af17-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f62d6d32-d298-11ec-af17-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f7602996-d298-11ec-85fc-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f7602996-d298-11ec-85fc-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/L.f89516de-d298-11ec-b989-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/L.f89516de-d298-11ec-b989-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.9d5a4216-c4de-11ec-9c9b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.9d5a4216-c4de-11ec-9c9b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.9fd0caca-c4de-11ec-8672-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.9fd0caca-c4de-11ec-8672-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a108312d-c4de-11ec-aa80-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a108312d-c4de-11ec-aa80-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a23e7d1d-c4de-11ec-9cb7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a23e7d1d-c4de-11ec-9cb7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a37881a2-c4de-11ec-9967-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a37881a2-c4de-11ec-9967-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a4af20f1-c4de-11ec-8924-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a4af20f1-c4de-11ec-8924-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a5e6a803-c4de-11ec-8aa9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a5e6a803-c4de-11ec-8aa9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a71b956c-c4de-11ec-8e3c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a71b956c-c4de-11ec-8e3c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/M.a8524344-c4de-11ec-8024-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/M.a8524344-c4de-11ec-8024-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.7f222822-d373-11ec-8a2f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.7f222822-d373-11ec-8a2f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.805a2096-d373-11ec-9494-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.805a2096-d373-11ec-9494-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.8192871a-d373-11ec-b4ad-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.8192871a-d373-11ec-b4ad-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.82c7cd36-d373-11ec-a1f8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.82c7cd36-d373-11ec-a1f8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.83fdeb1a-d373-11ec-9139-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.83fdeb1a-d373-11ec-9139-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.8534c834-d373-11ec-965f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.8534c834-d373-11ec-965f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.866ab328-d373-11ec-ad8a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.866ab328-d373-11ec-ad8a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.87a0148c-d373-11ec-91c7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.87a0148c-d373-11ec-91c7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.88d73a41-d373-11ec-83ac-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.88d73a41-d373-11ec-83ac-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.8a0c84d9-d373-11ec-918f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.8a0c84d9-d373-11ec-918f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.9a05717a-d373-11ec-a124-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.9a05717a-d373-11ec-a124-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.9c77062d-d373-11ec-b16e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.9c77062d-d373-11ec-b16e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.9dac6f4d-d373-11ec-86c3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.9dac6f4d-d373-11ec-86c3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.9ee234ac-d373-11ec-a480-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.9ee234ac-d373-11ec-a480-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.a01757dd-d373-11ec-ac14-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.a01757dd-d373-11ec-ac14-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.a14cd2bc-d373-11ec-b5ae-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.a14cd2bc-d373-11ec-b5ae-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.a28347a4-d373-11ec-9db3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.a28347a4-d373-11ec-9db3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.a3b9db89-d373-11ec-979a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.a3b9db89-d373-11ec-979a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.a4efa030-d373-11ec-ab01-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.a4efa030-d373-11ec-ab01-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.ee1f2555-c4de-11ec-bfea-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.ee1f2555-c4de-11ec-bfea-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.ef5c08a5-c4de-11ec-85ab-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.ef5c08a5-c4de-11ec-85ab-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f09301e8-c4de-11ec-aa13-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f09301e8-c4de-11ec-aa13-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f1c8517b-c4de-11ec-b82a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f1c8517b-c4de-11ec-b82a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f2fe549c-c4de-11ec-8201-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f2fe549c-c4de-11ec-8201-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f4331a86-c4de-11ec-8faf-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f4331a86-c4de-11ec-8faf-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f56b10c6-c4de-11ec-a60b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f56b10c6-c4de-11ec-a60b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f6a59fe9-c4de-11ec-8143-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f6a59fe9-c4de-11ec-8143-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f7dc4d3e-c4de-11ec-8041-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f7dc4d3e-c4de-11ec-8041-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/N.f9124ba7-c4de-11ec-80f6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/N.f9124ba7-c4de-11ec-80f6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.2388d28d-d372-11ec-bee5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.2388d28d-d372-11ec-bee5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.24c178fe-d372-11ec-9814-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.24c178fe-d372-11ec-9814-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.25f78366-d372-11ec-9be3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.25f78366-d372-11ec-9be3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.28648b5a-d372-11ec-a2ac-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.28648b5a-d372-11ec-a2ac-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.2ad0794c-d372-11ec-92d3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.2ad0794c-d372-11ec-92d3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.2c07027c-d372-11ec-9721-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.2c07027c-d372-11ec-9721-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.2d3bf373-d372-11ec-a2a8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.2d3bf373-d372-11ec-a2a8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.2e71c58d-d372-11ec-a525-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.2e71c58d-d372-11ec-a525-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.3a1dd454-c4df-11ec-ba0d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.3a1dd454-c4df-11ec-ba0d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.3b5b6e60-c4df-11ec-b23a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.3b5b6e60-c4df-11ec-b23a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.3c940246-c4df-11ec-8a5d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.3c940246-c4df-11ec-8a5d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.3dc8b642-c4df-11ec-8d9c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.3dc8b642-c4df-11ec-8d9c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.3efe506e-c4df-11ec-9a90-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.3efe506e-c4df-11ec-9a90-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.40354c8d-c4df-11ec-99dd-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.40354c8d-c4df-11ec-99dd-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.40f4f104-d372-11ec-9993-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.40f4f104-d372-11ec-9993-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.416b5ead-c4df-11ec-918b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.416b5ead-c4df-11ec-918b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.422aa7b5-d372-11ec-a283-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.422aa7b5-d372-11ec-a283-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.42a1f8a9-c4df-11ec-8931-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.42a1f8a9-c4df-11ec-8931-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.435f7ab9-d372-11ec-9d9b-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.435f7ab9-d372-11ec-9d9b-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.43d7d60a-c4df-11ec-aebb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.43d7d60a-c4df-11ec-aebb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.4493d186-d372-11ec-b229-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.4493d186-d372-11ec-b229-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.450ffed1-c4df-11ec-a3a7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.450ffed1-c4df-11ec-a3a7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.470010e0-d372-11ec-98c0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.470010e0-d372-11ec-98c0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.48361dc0-d372-11ec-a674-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.48361dc0-d372-11ec-a674-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.496a97b5-d372-11ec-9fd9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.496a97b5-d372-11ec-9fd9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/O.4aa06456-d372-11ec-b8f7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/O.4aa06456-d372-11ec-b8f7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.8ab228b7-d29b-11ec-879f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.8ab228b7-d29b-11ec-879f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.8be7d8d7-d29b-11ec-b3f5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.8be7d8d7-d29b-11ec-b3f5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.8d1e5193-d29b-11ec-9689-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.8d1e5193-d29b-11ec-9689-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.8e540a0d-d29b-11ec-8e03-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.8e540a0d-d29b-11ec-8e03-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.8f8b18e8-d29b-11ec-9606-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.8f8b18e8-d29b-11ec-9606-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.91f86d9a-d29b-11ec-8a99-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.91f86d9a-d29b-11ec-8a99-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.d388238a-d29b-11ec-9ed9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.d388238a-d29b-11ec-9ed9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.d4be0cd8-d29b-11ec-a10d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.d4be0cd8-d29b-11ec-a10d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.d5f2d332-d29b-11ec-8f1d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.d5f2d332-d29b-11ec-8f1d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.d728e528-d29b-11ec-8d1e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.d728e528-d29b-11ec-8d1e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.dac846e8-d29b-11ec-890d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.dac846e8-d29b-11ec-890d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/P.dbfca7f7-d29b-11ec-bda3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/P.dbfca7f7-d29b-11ec-bda3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.255d7bb8-c941-11ec-a83c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.255d7bb8-c941-11ec-a83c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.26922cdf-c941-11ec-ab4a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.26922cdf-c941-11ec-ab4a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.2b67859e-c941-11ec-b26e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.2b67859e-c941-11ec-b26e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.2c9cdf54-c941-11ec-82d0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.2c9cdf54-c941-11ec-82d0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4916f323-c941-11ec-81e7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4916f323-c941-11ec-81e7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4a4c8f82-c941-11ec-be8f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4a4c8f82-c941-11ec-be8f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4b825293-c941-11ec-8097-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4b825293-c941-11ec-8097-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4cb839f9-c941-11ec-a150-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4cb839f9-c941-11ec-a150-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4ded9de8-c941-11ec-a958-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4ded9de8-c941-11ec-a958-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.4f23001b-c941-11ec-8606-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.4f23001b-c941-11ec-8606-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Q.518d2908-c941-11ec-812d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Q.518d2908-c941-11ec-812d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2547a3cf-c943-11ec-bc38-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2547a3cf-c943-11ec-bc38-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.26818050-c943-11ec-8429-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.26818050-c943-11ec-8429-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.27b70a9c-c943-11ec-b87c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.27b70a9c-c943-11ec-b87c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.28eca449-c943-11ec-ade7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.28eca449-c943-11ec-ade7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2a22f15e-c943-11ec-89f5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2a22f15e-c943-11ec-89f5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2b583ecf-c943-11ec-91a5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2b583ecf-c943-11ec-91a5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2c8d2d4a-c943-11ec-8850-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2c8d2d4a-c943-11ec-8850-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2dc3f020-c943-11ec-9218-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2dc3f020-c943-11ec-9218-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.2ef87063-c943-11ec-b4ae-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.2ef87063-c943-11ec-b4ae-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.302ce8de-c943-11ec-9bce-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.302ce8de-c943-11ec-9bce-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.7da040f4-c94c-11ec-9152-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.7da040f4-c94c-11ec-9152-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.7eda33db-c94c-11ec-8446-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.7eda33db-c94c-11ec-8446-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.800e3764-c94c-11ec-af9e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.800e3764-c94c-11ec-af9e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.8278c60c-c94c-11ec-b414-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.8278c60c-c94c-11ec-b414-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.83ade6ff-c94c-11ec-b1a6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.83ade6ff-c94c-11ec-b1a6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.84e3e564-c94c-11ec-aefd-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.84e3e564-c94c-11ec-aefd-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.8618fa7a-c94c-11ec-a464-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.8618fa7a-c94c-11ec-a464-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.874ebbeb-c94c-11ec-8e2f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.874ebbeb-c94c-11ec-8e2f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.8883a48d-c94c-11ec-ac22-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.8883a48d-c94c-11ec-ac22-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.a228d1fb-c94c-11ec-884f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.a228d1fb-c94c-11ec-884f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/R.a96b54a7-c94c-11ec-9418-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/R.a96b54a7-c94c-11ec-9418-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.91ebbd75-c941-11ec-8523-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.91ebbd75-c941-11ec-8523-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.9456de82-c941-11ec-8efb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.9456de82-c941-11ec-8efb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.958cdd65-c941-11ec-99a2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.958cdd65-c941-11ec-99a2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.96c12f74-c941-11ec-a8c2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.96c12f74-c941-11ec-a8c2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.9a607223-c941-11ec-92e7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.9a607223-c941-11ec-92e7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d177df1d-c941-11ec-9d80-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d177df1d-c941-11ec-9d80-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d2afd7aa-c941-11ec-91a0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d2afd7aa-c941-11ec-91a0-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d64dd99e-c941-11ec-8872-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d64dd99e-c941-11ec-8872-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d783bf27-c941-11ec-bd39-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d783bf27-c941-11ec-bd39-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d8b7c2be-c941-11ec-bba2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d8b7c2be-c941-11ec-bba2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.d9ed0ad8-c941-11ec-b988-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.d9ed0ad8-c941-11ec-b988-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/S.dc567139-c941-11ec-a2a1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/S.dc567139-c941-11ec-a2a1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.9f9d31b0-d2a8-11ec-b4a3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.9f9d31b0-d2a8-11ec-b4a3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a0d9ebee-d2a8-11ec-8ac8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a0d9ebee-d2a8-11ec-8ac8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a345cef7-d2a8-11ec-9691-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a345cef7-d2a8-11ec-9691-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a47aa558-d2a8-11ec-8d81-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a47aa558-d2a8-11ec-8d81-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a5ae8ceb-d2a8-11ec-aad2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a5ae8ceb-d2a8-11ec-aad2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a6e3542e-d2a8-11ec-858a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a6e3542e-d2a8-11ec-858a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a817cb7f-d2a8-11ec-ab30-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a817cb7f-d2a8-11ec-ab30-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/space.a94c39e2-d2a8-11ec-a204-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/space.a94c39e2-d2a8-11ec-a204-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.098d4e90-d2ab-11ec-b8b1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.098d4e90-d2ab-11ec-b8b1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.0ac2a90a-d2ab-11ec-91a8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.0ac2a90a-d2ab-11ec-91a8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.0bf8aad4-d2ab-11ec-ad26-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.0bf8aad4-d2ab-11ec-ad26-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.0d2c37da-d2ab-11ec-9288-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.0d2c37da-d2ab-11ec-9288-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.0e604ab2-d2ab-11ec-a091-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.0e604ab2-d2ab-11ec-a091-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.0f95be08-d2ab-11ec-b21c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.0f95be08-d2ab-11ec-b21c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.10cb682f-d2ab-11ec-9764-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.10cb682f-d2ab-11ec-9764-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.11ff4943-d2ab-11ec-ae38-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.11ff4943-d2ab-11ec-ae38-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.1334344b-d2ab-11ec-abfa-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.1334344b-d2ab-11ec-abfa-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b1f4d450-d2aa-11ec-8629-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b1f4d450-d2aa-11ec-8629-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b45e5ac9-d2aa-11ec-9ade-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b45e5ac9-d2aa-11ec-9ade-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b5925975-d2aa-11ec-9b6d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b5925975-d2aa-11ec-9b6d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b6c778e6-d2aa-11ec-9de8-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b6c778e6-d2aa-11ec-9de8-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b7fc8d6d-d2aa-11ec-8468-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b7fc8d6d-d2aa-11ec-8468-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/T.b93181ba-d2aa-11ec-8926-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/T.b93181ba-d2aa-11ec-8926-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.91994796-c4e1-11ec-8ef6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.91994796-c4e1-11ec-8ef6-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.92d645e4-c4e1-11ec-9053-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.92d645e4-c4e1-11ec-9053-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.954355ee-c4e1-11ec-aa72-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.954355ee-c4e1-11ec-aa72-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.9678bf34-c4e1-11ec-adf5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.9678bf34-c4e1-11ec-adf5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.97b0a67c-c4e1-11ec-80af-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.97b0a67c-c4e1-11ec-80af-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.98e68b30-c4e1-11ec-a1da-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.98e68b30-c4e1-11ec-a1da-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.9a1c30bc-c4e1-11ec-ba20-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.9a1c30bc-c4e1-11ec-ba20-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.9c877ef8-c4e1-11ec-92ab-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.9c877ef8-c4e1-11ec-92ab-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.e3b4f61e-c942-11ec-9366-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.e3b4f61e-c942-11ec-9366-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.e4ee7173-c942-11ec-b5ba-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.e4ee7173-c942-11ec-b5ba-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.e62408fd-c942-11ec-8fe5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.e62408fd-c942-11ec-8fe5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.e75a0a21-c942-11ec-80e7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.e75a0a21-c942-11ec-80e7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.e88f19bf-c942-11ec-990c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.e88f19bf-c942-11ec-990c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.eaf92e2b-c942-11ec-95c3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.eaf92e2b-c942-11ec-95c3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.ec2e1bee-c942-11ec-9b22-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.ec2e1bee-c942-11ec-9b22-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.ed641a93-c942-11ec-bc3c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.ed641a93-c942-11ec-bc3c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/U.ee99cabf-c942-11ec-993d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/U.ee99cabf-c942-11ec-993d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.cc25fa83-c944-11ec-815c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.cc25fa83-c944-11ec-815c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.cd5a9a60-c944-11ec-a863-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.cd5a9a60-c944-11ec-a863-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.cfc54ec7-c944-11ec-a04f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.cfc54ec7-c944-11ec-a04f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.d0fcac90-c944-11ec-95a4-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.d0fcac90-c944-11ec-95a4-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.d231738b-c944-11ec-ae9e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.d231738b-c944-11ec-ae9e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.d36694fb-c944-11ec-b1e7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.d36694fb-c944-11ec-b1e7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.d49bf77b-c944-11ec-b511-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.d49bf77b-c944-11ec-b511-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.d5d10ce7-c944-11ec-a3ae-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.d5d10ce7-c944-11ec-a3ae-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.f3290e91-c944-11ec-b2e5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.f3290e91-c944-11ec-b2e5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.f45e234e-c944-11ec-a3b7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.f45e234e-c944-11ec-a3b7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.f59337e3-c944-11ec-a745-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.f59337e3-c944-11ec-a745-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.f7fdf7ff-c944-11ec-9a0c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.f7fdf7ff-c944-11ec-9a0c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.f932f5af-c944-11ec-baa2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.f932f5af-c944-11ec-baa2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/V.fa688eda-c944-11ec-a58d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/V.fa688eda-c944-11ec-a58d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.440f39cd-c4e2-11ec-9b54-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.440f39cd-c4e2-11ec-9b54-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.454949c3-c4e2-11ec-a9d3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.454949c3-c4e2-11ec-a9d3-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.467edd79-c4e2-11ec-a47f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.467edd79-c4e2-11ec-a47f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.47b4c9a8-c4e2-11ec-94de-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.47b4c9a8-c4e2-11ec-94de-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.48eb58fc-c4e2-11ec-aee1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.48eb58fc-c4e2-11ec-aee1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.4a22f269-c4e2-11ec-b4f9-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.4a22f269-c4e2-11ec-b4f9-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.4b587d69-c4e2-11ec-a964-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.4b587d69-c4e2-11ec-a964-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.4dc454f5-c4e2-11ec-854e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.4dc454f5-c4e2-11ec-854e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/W.4efa3ebc-c4e2-11ec-8eb7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/W.4efa3ebc-c4e2-11ec-8eb7-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.002baa19-c946-11ec-bb17-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.002baa19-c946-11ec-bb17-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.0160b8db-c946-11ec-8403-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.0160b8db-c946-11ec-8403-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d348da31-c945-11ec-8943-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d348da31-c945-11ec-8943-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d4832e20-c945-11ec-a312-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d4832e20-c945-11ec-a312-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d5b7b133-c945-11ec-b39f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d5b7b133-c945-11ec-b39f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d6ee24b8-c945-11ec-9511-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d6ee24b8-c945-11ec-9511-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d823e7ae-c945-11ec-8098-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d823e7ae-c945-11ec-8098-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.d9596ebf-c945-11ec-ba73-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.d9596ebf-c945-11ec-ba73-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.da8e3520-c945-11ec-a256-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.da8e3520-c945-11ec-a256-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.dbc318d6-c945-11ec-b16e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.dbc318d6-c945-11ec-b16e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.dcf841a5-c945-11ec-9134-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.dcf841a5-c945-11ec-9134-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.de2df24c-c945-11ec-828d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.de2df24c-c945-11ec-828d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.f67dabe6-c945-11ec-90bc-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.f67dabe6-c945-11ec-90bc-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.f7b6fbc8-c945-11ec-a9ef-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.f7b6fbc8-c945-11ec-a9ef-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.f8ec3848-c945-11ec-a36a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.f8ec3848-c945-11ec-a36a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.fa219bed-c945-11ec-ae3f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.fa219bed-c945-11ec-ae3f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.fb56c8de-c945-11ec-8446-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.fb56c8de-c945-11ec-8446-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.fc8c2bcb-c945-11ec-941f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.fc8c2bcb-c945-11ec-941f-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.fdc1193f-c945-11ec-bbf2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.fdc1193f-c945-11ec-bbf2-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/X.fef62d9a-c945-11ec-b553-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/X.fef62d9a-c945-11ec-b553-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.ab21cfae-c4e2-11ec-b163-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.ab21cfae-c4e2-11ec-b163-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.ac55aac2-c4e2-11ec-a9c5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.ac55aac2-c4e2-11ec-a9c5-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.ad898107-c4e2-11ec-82ad-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.ad898107-c4e2-11ec-82ad-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.aebf50f1-c4e2-11ec-baa1-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.aebf50f1-c4e2-11ec-baa1-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.aff423ea-c4e2-11ec-a667-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.aff423ea-c4e2-11ec-a667-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Y.b127d4ff-c4e2-11ec-947e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Y.b127d4ff-c4e2-11ec-947e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.78c6551d-c943-11ec-b95a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.78c6551d-c943-11ec-b95a-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.79fe9bf0-c943-11ec-a8fb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.79fe9bf0-c943-11ec-a8fb-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.7b3499fd-c943-11ec-b08d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.7b3499fd-c943-11ec-b08d-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.7c6960e6-c943-11ec-bbdf-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.7c6960e6-c943-11ec-bbdf-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.7d9d9a76-c943-11ec-8d6e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.7d9d9a76-c943-11ec-8d6e-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.7ed35ebd-c943-11ec-8b9c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.7ed35ebd-c943-11ec-8b9c-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.8008ea0b-c943-11ec-99e4-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.8008ea0b-c943-11ec-99e4-04d4c4df202e.xml\n","Tensorflow/workspace/images/train/Z.83a717f3-c943-11ec-8a71-04d4c4df202e.jpg\n","Tensorflow/workspace/images/train/Z.83a717f3-c943-11ec-8a71-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/\n","Tensorflow/workspace/images/test/A.cc99f873-c939-11ec-959e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/A.cc99f873-c939-11ec-959e-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/A.f7057c11-c939-11ec-b765-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/A.f7057c11-c939-11ec-b765-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/B.20bb59fa-c4d6-11ec-8f60-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/B.20bb59fa-c4d6-11ec-8f60-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/B.329d5a0b-c93a-11ec-bf3f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/B.329d5a0b-c93a-11ec-bf3f-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/C.644b79a3-c93a-11ec-8c42-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/C.644b79a3-c93a-11ec-8c42-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/C.86d42d88-c93a-11ec-9e2f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/C.86d42d88-c93a-11ec-9e2f-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/D279.jpg\n","Tensorflow/workspace/images/test/D279.xml\n","Tensorflow/workspace/images/test/D280.jpg\n","Tensorflow/workspace/images/test/D280.xml\n","Tensorflow/workspace/images/test/del.b230cc67-c4e3-11ec-a849-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/del.b230cc67-c4e3-11ec-a849-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/del.b49d1f61-c4e3-11ec-803a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/del.b49d1f61-c4e3-11ec-803a-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/E.0bfeaf55-c93c-11ec-9d37-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/E.0bfeaf55-c93c-11ec-9d37-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/E.12095774-c93c-11ec-b425-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/E.d8cc0419-c93b-11ec-ab20-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/E.d8cc0419-c93b-11ec-ab20-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/F.798964f0-c93c-11ec-9376-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/F.798964f0-c93c-11ec-9376-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/F.984745a0-c93c-11ec-8b5e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/F.984745a0-c93c-11ec-8b5e-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/G.44bcc17a-c93d-11ec-a070-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/G.44bcc17a-c93d-11ec-a070-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/G.71dcc6e1-c93d-11ec-a1e6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/G.71dcc6e1-c93d-11ec-a1e6-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/H.ad5bbada-c93d-11ec-84dd-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/H.ad5bbada-c93d-11ec-84dd-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/H.d0f0409c-c93d-11ec-8310-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/H.d0f0409c-c93d-11ec-8310-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/I.30dc6185-c93e-11ec-84bb-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/I.30dc6185-c93e-11ec-84bb-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/I.69ebb3c3-c93e-11ec-ae29-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/I.69ebb3c3-c93e-11ec-ae29-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/J.18c72c3e-c93f-11ec-932a-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/J.18c72c3e-c93f-11ec-932a-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/J.1c690f5c-c93f-11ec-95f3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/J.1c690f5c-c93f-11ec-95f3-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/K.09bb5993-c4de-11ec-921d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/K.09bb5993-c4de-11ec-921d-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/K.689b9e91-c93f-11ec-b948-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/K.689b9e91-c93f-11ec-b948-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/L.10483e20-d299-11ec-9418-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/L.10483e20-d299-11ec-9418-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/L.f3c05db5-d298-11ec-b9ec-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/L.f3c05db5-d298-11ec-b9ec-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/M.9fd0caca-c4de-11ec-8672-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/M.9fd0caca-c4de-11ec-8672-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/M.a4af20f1-c4de-11ec-8924-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/M.a4af20f1-c4de-11ec-8924-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/N.f6a59fe9-c4de-11ec-8143-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/N.f6a59fe9-c4de-11ec-8143-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/N.f7dc4d3e-c4de-11ec-8041-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/N.f7dc4d3e-c4de-11ec-8041-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/O.3c940246-c4df-11ec-8a5d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/O.3c940246-c4df-11ec-8a5d-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/O.3dc8b642-c4df-11ec-8d9c-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/O.3dc8b642-c4df-11ec-8d9c-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/P.8ab228b7-d29b-11ec-879f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/P.8ab228b7-d29b-11ec-879f-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/P.8be7d8d7-d29b-11ec-b3f5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/P.8be7d8d7-d29b-11ec-b3f5-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Q.4916f323-c941-11ec-81e7-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Q.4916f323-c941-11ec-81e7-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Q.518d2908-c941-11ec-812d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Q.518d2908-c941-11ec-812d-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/R.8618fa7a-c94c-11ec-a464-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/R.8618fa7a-c94c-11ec-a464-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/R.a96b54a7-c94c-11ec-9418-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/R.a96b54a7-c94c-11ec-9418-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/S.992b5370-c941-11ec-b168-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/S.992b5370-c941-11ec-b168-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/S.d3e4881d-c941-11ec-bd42-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/S.d3e4881d-c941-11ec-bd42-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/space.a47aa558-d2a8-11ec-8d81-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/space.a47aa558-d2a8-11ec-8d81-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/space.a817cb7f-d2a8-11ec-ab30-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/space.a817cb7f-d2a8-11ec-ab30-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/T.08548f28-d2ab-11ec-ac33-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/T.08548f28-d2ab-11ec-ac33-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/T.b32a0808-d2aa-11ec-8b4d-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/T.b32a0808-d2aa-11ec-8b4d-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/U.9b51ea0f-c4e1-11ec-8d53-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/U.9b51ea0f-c4e1-11ec-8d53-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/U.e9c5777f-c942-11ec-a642-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/U.e9c5777f-c942-11ec-a642-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/V.ce8f8a2b-c944-11ec-b1e0-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/V.ce8f8a2b-c944-11ec-b1e0-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/V.f1f495fe-c944-11ec-b5a6-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/V.f1f495fe-c944-11ec-b5a6-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/W.454949c3-c4e2-11ec-a9d3-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/W.454949c3-c4e2-11ec-a9d3-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/W.467edd79-c4e2-11ec-a47f-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/W.467edd79-c4e2-11ec-a47f-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/X.da8e3520-c945-11ec-a256-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/X.da8e3520-c945-11ec-a256-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/X.dbc318d6-c945-11ec-b16e-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/X.dbc318d6-c945-11ec-b16e-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Y.ab21cfae-c4e2-11ec-b163-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Y.ab21cfae-c4e2-11ec-b163-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Y.ac55aac2-c4e2-11ec-a9c5-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Y.ac55aac2-c4e2-11ec-a9c5-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Z.813d89f2-c943-11ec-a0fe-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Z.813d89f2-c943-11ec-a0fe-04d4c4df202e.xml\n","Tensorflow/workspace/images/test/Z.82727811-c943-11ec-b3d2-04d4c4df202e.jpg\n","Tensorflow/workspace/images/test/Z.82727811-c943-11ec-b3d2-04d4c4df202e.xml\n"]}],"source":["# OPTIONAL IF RUNNING ON COLAB\n","ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n","if os.path.exists(ARCHIVE_FILES):\n","  !tar -zxvf {ARCHIVE_FILES}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWpb_BVUpfDD"},"outputs":[],"source":["if not os.path.exists(files['TF_RECORD_SCRIPT']):\n","    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKhlxwwAKSbx"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7839,"status":"ok","timestamp":1652550053996,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"UPFToGZqpfDD","outputId":"7ea2a988-ba6f-4e3a-e478-1f93b2592a92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n","Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"]}],"source":["!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n","!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "]},{"cell_type":"markdown","metadata":{"id":"qT4QU7pLpfDE"},"source":["# 4. Copy Model Config to Training Folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOjuTFbwpfDF"},"outputs":[],"source":["if os.name =='posix':\n","    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n","if os.name == 'nt':\n","    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"]},{"cell_type":"markdown","metadata":{"id":"Ga8gpNslpfDF"},"source":["# 5. Update Config For Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9hRrO_ppfDF"},"outputs":[],"source":["import tensorflow as tf\n","from object_detection.utils import config_util\n","from object_detection.protos import pipeline_pb2\n","from google.protobuf import text_format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2A0mn4ipfDF"},"outputs":[],"source":["config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1652550060119,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"uQA13-afpfDF","outputId":"4badde61-c8f4-4731-d1c9-265143198e1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     fixed_shape_resizer {\n","       height: 320\n","       width: 320\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_mobilenet_v2_fpn_keras\"\n","     depth_multiplier: 1.0\n","     min_depth: 16\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         random_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.009999999776482582\n","         }\n","       }\n","       activation: RELU_6\n","       batch_norm {\n","         decay: 0.996999979019165\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","     }\n","     use_depthwise: true\n","     override_base_feature_extractor_hyperparams: true\n","     fpn {\n","       min_level: 3\n","       max_level: 7\n","       additional_layer_depth: 128\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: RELU_6\n","         batch_norm {\n","           decay: 0.996999979019165\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","       }\n","       depth: 128\n","       num_layers_before_predictor: 4\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       share_prediction_tower: true\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 2\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.6000000238418579\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","       use_static_shapes: false\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 2.0\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_crop_image {\n","     min_object_covered: 0.0\n","     min_aspect_ratio: 0.75\n","     max_aspect_ratio: 3.0\n","     min_area: 0.75\n","     max_area: 1.0\n","     overlap_thresh: 0.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 50000\n","         warmup_learning_rate: 0.026666000485420227\n","         warmup_steps: 1000\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n"," num_steps: 50000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED\"\n"," }}"]},"metadata":{},"execution_count":23}],"source":["config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vK5lotDpfDF"},"outputs":[],"source":["pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n","    proto_str = f.read()                                                                                                                                                                                                                                          \n","    text_format.Merge(proto_str, pipeline_config)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rP43Ph0JpfDG"},"outputs":[],"source":["pipeline_config.model.ssd.num_classes = len(labels)\n","pipeline_config.train_config.batch_size = 8\n","pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n","pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n","pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n","pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJvfgwWqpfDG"},"outputs":[],"source":["config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n","with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n","    f.write(config_text)   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7113,"status":"ok","timestamp":1652550067165,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"IaRUoJCzQq_3","outputId":"ba769d83-d297-4973-ccc7-436303150109"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python-headless 4.5.2.52\n","Uninstalling opencv-python-headless-4.5.2.52:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.2.52.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-8daa01ff.so.58.109.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-06a336f2.so.58.61.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-01d48d95.so.56.60.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-098682aa.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-c2ffaf3d.so.15.13.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-f3db6a3b.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-4767dc06.so.3.8.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-2d2bce5d.so.5.8.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-14094576.so.6.3.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libz-d8a329de.so.1.2.7\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.5.2.52\n"]}],"source":["pip uninstall opencv-python-headless==4.5.5.62"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4976,"status":"ok","timestamp":1652550072123,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"ubB8mZtAQw32","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f80a5515-5dbb-46bf-dda4-a84030031b0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless==4.5.2.52\n","  Using cached opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.5.2.52\n"]}],"source":["pip install opencv-python-headless==4.5.2.52\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2eVfYmkQ0fv"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-Y2UQmQpfDG"},"outputs":[],"source":["TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMP2XDfQpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=50000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652550504215,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"A4OXXi-ApfDH","outputId":"11ac852e-7b70-4039-cceb-40fed1090cc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/myss_mobilenet_colab2 --pipeline_config_path=Tensorflow/workspace/models/myss_mobilenet_colab2/pipeline.config --num_train_steps=50000\n"]}],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSNkPjuUe8Xx"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3ZsJR-qpfDH","executionInfo":{"status":"ok","timestamp":1652558276200,"user_tz":-330,"elapsed":13,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"}},"outputId":"3d06db44-cafb-4788-a864-e48d97b45b7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: {command}: command not found\n"]}],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"4_YRZu7npfDH"},"source":["# 7. Evaluate the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80L7-fdPpfDH"},"outputs":[],"source":["command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYsgEPx9pfDH"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqTV2jGBpfDH"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"orvRk02UpfDI"},"source":["# 8. Load Train Model From Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TYk4_oIpfDI"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":658},"executionInfo":{"elapsed":3016,"status":"error","timestamp":1652550460978,"user":{"displayName":"Jotdeep Singh Ahluwalia","userId":"13726573984400235667"},"user_tz":-330},"id":"tDnQg-cYpfDI","outputId":"c1194ac4-f78a-4f8f-b034-61d4cdf1eada"},"outputs":[{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/myss_mobilenet_colab2/ckpt-21","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2259\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2260\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2261\u001b[0m     metrics.AddCheckpointReadDuration(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1343\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mInitializationOnlyStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0mgraph_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     30\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n","\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/myss_mobilenet_colab2/ckpt-21","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-d48ae36b0758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Restore checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHECKPOINT_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ckpt-21'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2384\u001b[0m       raise errors_impl.NotFoundError(\n\u001b[1;32m   2385\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2386\u001b[0;31m           \u001b[0;34mf\"Error when restoring from checkpoint or SavedModel at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2387\u001b[0m           \u001b[0;34mf\"{orig_save_path}: {e.message}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m           \u001b[0;34mf\"\\nPlease double-check that the path is correct. You may be missing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Error when restoring from checkpoint or SavedModel at Tensorflow/workspace/models/myss_mobilenet_colab2/ckpt-21: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for Tensorflow/workspace/models/myss_mobilenet_colab2/ckpt-21\nPlease double-check that the path is correct. You may be missing the checkpoint suffix (e.g. the '-1' in 'path/to/ckpt-1')."]}],"source":["# Load pipeline config and build a detection model\n","configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n","detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-21')).expect_partial()\n","\n","@tf.function\n","def detect_fn(image):\n","    image, shapes = detection_model.preprocess(image)\n","    prediction_dict = detection_model.predict(image, shapes)\n","    detections = detection_model.postprocess(prediction_dict, shapes)\n","    return detections"]},{"cell_type":"markdown","metadata":{"id":"0EmsmbBZpfDI"},"source":["# 9. Detect from an Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_MKiuZ4pfDI"},"outputs":[],"source":["import cv2 \n","import numpy as np\n","from matplotlib import pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBDbIhNapfDI"},"outputs":[],"source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lx3crOhOzITB"},"outputs":[],"source":["IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'E.d8cc0419-c93b-11ec-ab20-04d4c4df202e.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tpzn1SMry1yK"},"outputs":[],"source":["img = cv2.imread(IMAGE_PATH)\n","image_np = np.array(img)\n","\n","input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","detections = detect_fn(input_tensor)\n","\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","              for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","label_id_offset = 1\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","            image_np_with_detections,\n","            detections['detection_boxes'],\n","            detections['detection_classes']+label_id_offset,\n","            detections['detection_scores'],\n","            category_index,\n","            use_normalized_coordinates=True,\n","            max_boxes_to_draw=5,\n","            min_score_thresh=.8,\n","            agnostic_mode=False)\n","\n","plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"IsNAaYAo0WVL"},"source":["# 10. Real Time Detections from your Webcam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbuBX62oMo4c"},"outputs":[],"source":["!pip uninstall opencv-python-headless -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_grs6OGpfDJ"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","while cap.isOpened(): \n","    ret, frame = cap.read()\n","    image_np = np.array(frame)\n","    \n","    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n","    detections = detect_fn(input_tensor)\n","    \n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","                image_np_with_detections,\n","                detections['detection_boxes'],\n","                detections['detection_classes']+label_id_offset,\n","                detections['detection_scores'],\n","                category_index,\n","                use_normalized_coordinates=True,\n","                max_boxes_to_draw=5,\n","                min_score_thresh=.8,\n","                agnostic_mode=False)\n","\n","    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n","    \n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        cap.release()\n","        cv2.destroyAllWindows()\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SyaQ2Jrnl8A"},"outputs":[],"source":["!zip -r /content/file.zip /content/Tensorflow/workspace/models/my_ssd_mobnet"]},{"cell_type":"markdown","metadata":{"id":"rzlM4jt0pfDJ"},"source":["# 10. Freezing the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4olHB2npfDJ"},"outputs":[],"source":["FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AjO93QDpfDJ"},"outputs":[],"source":["command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6Lsp3tCpfDJ"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Sw1ULgHpfDJ"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"wTPmdqaXpfDK"},"source":["# 11. Conversion to TFJS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ6UzY_fpfDK","scrolled":true},"outputs":[],"source":["!pip install tensorflowjs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oxbVynHpfDK"},"outputs":[],"source":["command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB2AGNmJpfDK"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7rfT4-hpfDK"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8_hm-itpfDK"},"outputs":[],"source":["# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"]},{"cell_type":"markdown","metadata":{"id":"VtUw73FHpfDK"},"source":["# 12. Conversion to TFLite"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XviMtewLpfDK"},"outputs":[],"source":["TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us86cjC4pfDL"},"outputs":[],"source":["command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1r5YO3rpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-xWpHN8pfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJfYMbN6pfDL"},"outputs":[],"source":["FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n","TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_a1fdKqMo4i"},"outputs":[],"source":["command = \"tflite_convert \\\n","--saved_model_dir={} \\\n","--output_file={} \\\n","--input_shapes=1,300,300,3 \\\n","--input_arrays=normalized_input_image_tensor \\\n","--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n","--inference_type=FLOAT \\\n","--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8GwUeoFpfDL"},"outputs":[],"source":["print(command)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nbd7gqHMpfDL"},"outputs":[],"source":["!{command}"]},{"cell_type":"markdown","metadata":{"id":"5NQqZRdA21Uc"},"source":["# 13. Zip and Export Models "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTVTGCQp2ZJJ"},"outputs":[],"source":["!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whShhB0x3PYJ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["0EmsmbBZpfDI","IsNAaYAo0WVL","rzlM4jt0pfDJ","wTPmdqaXpfDK","VtUw73FHpfDK","5NQqZRdA21Uc"],"name":"Copy of Copy of Copy of 3. Training and Detection.ipynb","provenance":[{"file_id":"1biQAwnw4ttfaoQuTDL1_x4kzhpiakyn7","timestamp":1652587171418},{"file_id":"16pUPH0eQJcj6RI2PB47TvbLclnAUjtFi","timestamp":1652453776250},{"file_id":"https://github.com/nicknochnack/TFODCourse/blob/main/2.%20Training%20and%20Detection.ipynb","timestamp":1652433062661}],"history_visible":true},"kernelspec":{"display_name":"tfod","language":"python","name":"tfod"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}